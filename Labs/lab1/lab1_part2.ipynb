{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab1_part2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bxGkToGpFrJ"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/KhaledElTahan/DeepLearning/blob/master/Labs/lab1/lab1_part2.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6OFYzfbpHX6"
      },
      "source": [
        "# Copyright Information\r\n",
        "\r\n",
        "**Parts of this lab are based on Kaggle kernels.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA5NHvtepVUX"
      },
      "source": [
        "# Lab 1 - Part2: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JgGI_Q82Dor"
      },
      "source": [
        "![Logistic Regression](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/logistic_regression.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbWcnTT02NPV"
      },
      "source": [
        "## 1.2.1 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhU6-7Mx2TVB"
      },
      "source": [
        "Here, we are trying to increase the peoplesâ€™ attention regarding the heart diseases. Like any disease, it is always better to know if you are sick early so you can get the treatment you need before it is too late. Therefore, we use a dataset that gathered some information about two groups: a group with a heart disease and the other group has no disease.\r\n",
        "The gathered information includes age, chest pain type, fasting blood sugar, etc. \r\n",
        "\r\n",
        "Your goal is to train a logistic regression model to predict if a person has a heart disease or not depending on the given information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTcUN4K24pK"
      },
      "source": [
        "## 1.2.2 Problem Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofHL4e073Ca0"
      },
      "source": [
        "Let's dive into the code, explain it and show you the parts you need to fill!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjQNwFqC4NEM"
      },
      "source": [
        "### 1.2.2.1 Import Needed packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0AnpII84Pdw"
      },
      "source": [
        "Pay close attention to the packages I imported for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0_d4RG4zcC_"
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation\r\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, RMSprop\r\n",
        "from tensorflow.keras.initializers import RandomNormal, RandomUniform\r\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalHinge\r\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGBlsWk4ner"
      },
      "source": [
        "### 1.2.2.2 Work on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR6WYKSo5tRH"
      },
      "source": [
        "This dataset contains 13 features that demonstrate the health state of a person and our target (0 if this person does not have a heart disease and 1 if he has a heart disease.)\r\n",
        "\r\n",
        "We first load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxqN_IPo6Fg"
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab1/lab1_heart.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGsChzk_55nr"
      },
      "source": [
        "A sneak peak on the dataset and how it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRQkXsiHrTBB"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJa4KJEV6AFm"
      },
      "source": [
        "Define input and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1UDjkHZrbey"
      },
      "source": [
        "X = dataset.iloc[:, 0:13].values\r\n",
        "y = dataset.iloc[:, 13].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTd_AkXK6Y1G"
      },
      "source": [
        "**Experiment with the model as much as possible and try to obtain best results (follow the TODOs)**",
        "**TODO: Preprocess your data**\n",
        "\n",
        "1.   Do you need to scale the data? Which type of scaling is better? \n",
        "2.   Perhaps you might want to add non-linearity by adding artificial features.\n",
        "\n",
        "![The effect of the boundary with artificial features](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/artificial_features_boundaries.png)\n",
        "\n",
        "You might have a look on part1 preprocessing and take hints from there. \n",
        "\n",
        "**Try different types of data preprocessing (and try combining them) and include their effect on the accuracy in your report.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyDjY4ECpenA"
      },
      "source": [
        "x = # TODO: Data Pre-Processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6Cy9ar6ewP"
      },
      "source": [
        "Split dataset into, training, validation and testing splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCBELT8wpsrq"
      },
      "source": [
        "# Get Training Data\r\n",
        "train_X, temporary_X, train_y, temporary_y = train_test_split(X, y, train_size=0.75, random_state=0)\r\n",
        "\r\n",
        "# Get Validation & Testing Data\r\n",
        "val_X, test_X, val_y, test_y = train_test_split(temporary_X, temporary_y, train_size=0.5, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk5uv_H26p5M"
      },
      "source": [
        "### 1.2.2.3 Define your model here (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eWXVX966kiM"
      },
      "source": [
        "Logistic Regression as a model is exactly like the Linear Regression except for the activation function. \n",
        "\n",
        "Use this fact to define your model similar to part1 except for the actication function.\n",
        "\n",
        "![Logistic Regression using Simple Perceptron](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/perceptron_activation.png)\n",
        "\n",
        
        "**TODO**: \n",
        "1. Try different activation functions (one more other than sigmoid at least, you are encouraged to try more) and include in the report their effect on the accuracy\n", 
        "(note that sigmoid is most suitable for binary classification, however experiment to see the effect of others).\n",
        "2. Try different regularizers (two or more) and include in the report their effect on the accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqJwVMxdptTz"
      },
      "source": [
        "activation = 'sigmoid'\r\n",
        "regularizer = regularizers.l2(0.01)\r\n",
        "\r\n",
        "model = # TODO: Define the Model using Tensorflow.Keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFHo5TzW_yCw"
      },
      "source": [
        "### 1.2.2.4 Compile your model and print a summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoaNNu-z6m2j"
      },
      "source": [
        "**TODO**\r\n",
        "1. Try different losses functions (try 2 different loss functions) and include in the report their effect on the accuracy. **Make sure that those losses functions are meant only for classification! Don't use losses functions that are meant for prediction!**\r\n",
        "2. Try different optimizers (2 or more) and include in the report their effect on the accuracy and the training plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5WXiT2kpv66"
      },
      "source": [
        "## TODO Try Different losses & optimizers here\r\n",
        "model.compile(loss=BinaryCrossentropy(), metrics=['accuracy'], optimizer=Adam())\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcTmEu8AAA4W"
      },
      "source": [
        "### 1.2.2.5 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBhupRN6_39e"
      },
      "source": [
        "hist = model.fit(train_X, train_y, verbose=1, validation_data=(val_X, val_y), batch_size=16, epochs=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mx4N7uO-9Uy"
      },
      "source": [
        "Evaluate your testing split, to get the accuracy and the loss score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Jzj9resfZF"
      },
      "source": [
        "score, accuracy = model.evaluate(test_X, test_y, batch_size=16, verbose=0)\r\n",
        "print(\"Test fraction correct (NN-Score) = {:.2f}\".format(score))\r\n",
        "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YaAr-aeAHBW"
      },
      "source": [
        "### 1.2.2.6 Visualize Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-h-R6YS_Ptd"
      },
      "source": [
        "Plot the training and validation accuracy. Try to interpret those plots. \r\n",
        "\r\n",
        "\r\n",
        "**TODO: for each experiment you make, include this plot and indicate whether there exist any type of overfitting or underfitting.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0eaLehNp0ES"
      },
      "source": [
        "# Get training and test loss histories\r\n",
        "training_loss = hist.history['accuracy']\r\n",
        "val_loss = hist.history['val_accuracy']\r\n",
        "\r\n",
        "# Create count of the number of epochs\r\n",
        "epoch_count = range(1, len(training_loss) + 1)\r\n",
        "\r\n",
        "# Visualize loss history\r\n",
        "plt.figure()\r\n",
        "plt.plot(epoch_count, training_loss, 'r--')\r\n",
        "plt.plot(epoch_count, val_loss, 'b-')\r\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vr8s80Aljv"
      },
      "source": [
        "## 1.2.3 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK6q-eIkAqmG"
      },
      "source": [
        "That's it! Congratulations on training a logistic regression model.\r\n",
        "\r\n",
        "Make sure you deliver all the requirements for the submission."
      ]
    }
  ]
}
