# Lab5: Visual Image Captioning

![Visual Image Captioning](Image_Captioning.png)

## 1 - Objectives

* Building a Seq2Seq model for image captioning based on CNN and RNN.
* Implementing the attention mechanism and integrating it with the model.
* Learning how to deal with datasets that do not fit into RAM.
* Working with few tensorflow parts instead of tf.Keras.

## 2 - Requirements

* Solve [this notebook](lab5.ipynb) of the assignment and deliver a filled ipython notebook that shows the best output found in your experiments. **Check the hints in the notebook to help guide you while filling in the code**.
* Download the notebook and upload it for submission. **Make sure you include the output of the cells, especially the predicted caption on a test image in the evaluation section at the end** 
* No report is required.