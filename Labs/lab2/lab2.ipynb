{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1--VwHLHB20Y"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/KhaledElTahan/DeepLearning/blob/master/Labs/lab2/lab2.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXkKT_UeCGgB"
      },
      "source": [
        "# Lab 2: Multinominal Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LkqxKonD2oV"
      },
      "source": [
        "![Multinominal Classification Network](https://github.com/KhaledElTahan/DeepLearning/blob/master/Labs/lab2/multinominal_classification_net.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz5Sop66C2Li"
      },
      "source": [
        "## 2.1 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP9r6HwqEX1Q"
      },
      "source": [
        "In this lab we will be addressing the task of multinominal classification of handwritten digits from the famous MNIST dataset. \n",
        "\n",
        "The MNIST dataset consists of 60,000 training images and 10,000 test images.  Our classes are the digits 0-9.\n",
        "\n",
        "You are required to build 2 models to solve this problem:\n",
        "1. A simple using fully connected layers.\n",
        "2. A model using Convolutional Neural Network (CNN) before applying the simple model.\n",
        "\n",
        "You should perform different experiments on the two models, observe the difference in **accuracy** and report them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ES5CaaC9Dc"
      },
      "source": [
        "## 2.2 Problem Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRftyAl1Jsvi"
      },
      "source": [
        "### 2.2.1 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwfZNpB1KCoC"
      },
      "source": [
        "#### Import Needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMziyw2dI1rL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from progressbar import progressbar\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtavW6-AKIAP"
      },
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BQYYUQAKLE8"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (val_images, val_labels) = mnist.load_data()\n",
        "\n",
        "train_images = np.expand_dims(train_images, axis=-1) / 255.\n",
        "train_labels = np.int64(train_labels)\n",
        "\n",
        "val_images = np.expand_dims(val_images, axis=-1) / 255.\n",
        "val_labels = np.int64(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYcbif4KN6Y"
      },
      "source": [
        "#### Plot Dataset Sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A808Xk92KSF1"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "random_inds = np.random.choice(60000, 36)\n",
        "for i in range(36):\n",
        "    plt.subplot(6, 6, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image_ind = random_inds[i]\n",
        "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[image_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8MgsliHIizk"
      },
      "source": [
        "### 2.2.1 Fully Connected Neural Network Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY4CNyvYIq7s"
      },
      "source": [
        "Build a neural network, using tf.keras, consisting of 2 fully connected layers and apply this to the digit classification task, Our network will ultimately output a probability distribution over the 10 digit classes (0-9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOHgt6DSNY3m"
      },
      "source": [
        "![Two Layer Neural Network](https://github.com/KhaledElTahan/DeepLearning/blob/master/Labs/lab2/2layer_nn.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgi7HfFnVc1O"
      },
      "source": [
        "#### Define the Two-Layer Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOQxFyWnSSW1"
      },
      "source": [
        "**TODO** \n",
        "\n",
        "1. Define two layer neural network exactly as in the previous figure by adding two [dense layers](https://keras.io/api/layers/core_layers/dense/).\n",
        "2. Try different [activation functions](https://keras.io/api/layers/#layer-activations) for both layers (ReLU, Tanh, and other activations for first layer - Softmax, and other activations for output layer), and report the difference in **accuracy** and plots.\n",
        "3. Try different [regularization kernerls](https://keras.io/api/layers/#layer-weight-regularizers), and [regularization layers](https://keras.io/api/layers/#regularization-layers) (L1, L2, Dropout, and other regularizations), and report the difference in **accuracy** and plots. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNZ4WLDvIgpz"
      },
      "source": [
        "def build_fc_model():\n",
        "  fc_model = tf.keras.Sequential([\n",
        "      # First define a Flatten layer\n",
        "      tf.keras.layers.Flatten(),\n",
        "      # '''TODO: Define the first fully connected layer. Try different activation functions.'''\n",
        "\n",
        "      # '''TODO: Define the second Dense layer to output the classification probabilities. Try different activation functions.'''\n",
        " \n",
        "  ])\n",
        "  return fc_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifykalRnViiL"
      },
      "source": [
        "#### Compile the Two-Layer Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oesqneR6UQHo"
      },
      "source": [
        "**TODO** \n",
        "\n",
        "1. Try different [optimizers](https://keras.io/api/optimizers/), and report the difference in **accuracy** and plots.\n",
        "2. For each optimizer, try different learning rates and other hyperparameters (If applicable), and report the difference in **accuracy** and plots.\n",
        "3. Try different [loss functions](https://keras.io/api/losses/), and report the difference in **accuracy** and plots. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hp9o_I_IhHU"
      },
      "source": [
        "fc_model = build_fc_model()\n",
        "\n",
        "'''TODO: Experiment with different optimizers and learning rates. Think about how do these affect\n",
        "    the accuracy of the trained model? Which optimizers and/or learning rates yield\n",
        "    the best performance?'''\n",
        "fc_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#### Print the Two-Layer Neural Network Model Summary"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "tCsr4pUKDsIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj85YRrwDsIG"
      },
      "outputs": [],
      "source": [
        "fc_model.build((None, train_images.shape[1], train_images.shape[2], train_images.shape[3]))\n",
        "fc_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lor9fZcVaBJK"
      },
      "source": [
        "#### Train the Two-Layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkfGLP2ZUFqB"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "nn_hist = fc_model.fit(train_images, train_labels, validation_data=(val_images, val_labels), batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bp0QXiTah5g"
      },
      "source": [
        "#### Plot the Accuracy Curve for the Two-Layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BXjWxM9csaD"
      },
      "source": [
        "# Get training and validation accuracy histories\n",
        "training_acc = nn_hist.history['accuracy']\n",
        "val_acc = nn_hist.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, EPOCHS + 1)\n",
        "\n",
        "# Visualize accuracy history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count, val_acc, 'b-')\n",
        "plt.legend(['2L NN Training Accuracy', '2L NN Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Two-Layer NN Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OfdyyBmaZXa"
      },
      "source": [
        "#### Evaluate the Two-Layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20D8vG-cXx0"
      },
      "source": [
        "val_loss, val_acc = fc_model.evaluate(val_images, val_labels)\n",
        "\n",
        "print('Validation Accuracy:', val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yn7byOgfw_Z"
      },
      "source": [
        "### 2.2.2 Convolutional Neural Network Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs3kSt23gHeI"
      },
      "source": [
        "Build a CNN, using tf.keras, composed of two convolutional layers and pooling layers, followed by two fully connected layers, and ultimately output a probability distribution over the 10 digit classes (0-9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33A9PM6lgH4b"
      },
      "source": [
        "![CNN Model](https://github.com/KhaledElTahan/DeepLearning/blob/master/Labs/lab2/cnn_model.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2kJtj00ij7-"
      },
      "source": [
        "#### Define the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9tBnp8jiuju"
      },
      "source": [
        "**TODO** \n",
        "\n",
        "1. Define the convolutional network exactly as in the previous figure by adding two [dense layers](https://keras.io/api/layers/core_layers/dense/).\n",
        "2. Try different [activation functions](https://keras.io/api/layers/#layer-activations) for both layers (ReLU, Tanh, and other activations for first layer - Softmax, and other activations for output layer), and report the difference in **accuracy** and plots.\n",
        "3. Try different [regularization kernerls](https://keras.io/api/layers/#layer-weight-regularizers), and [regularization layers](https://keras.io/api/layers/#regularization-layers) (L1, L2, Dropout, and other regularizations), and report the difference in **accuracy** and plots. \n",
        "4. Try different [convolution filter sizes](https://keras.io/api/layers/convolution_layers/convolution2d/), and report the difference in accuracy and plots.\n",
        "5. For each convolution filter, try different stride lengthes, and report the difference in accuracy and plots.\n",
        "6. Try different [pooling layers](https://keras.io/api/layers/pooling_layers/) (i.e. change first and second pooling layers into other different pooling layers), and report the difference in accuracy and plots.\n",
        "\n",
        "**NOTE: Variations for the filter sizes, stride lengths and pooling layers, will mean of course that you will have to use different number of units for the next layers (i.e. you won't stick to the above mentioned figure once you try those variations).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnDMWshFgILm"
      },
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "\n",
        "        #'''TODO: Define the dimensions of the first convolutional layer according to the figure: Replace the _'''\n",
        "        tf.keras.layers.Conv2D(filters=_ , kernel_size=(_,_), input_shape=(_,_,_), activation=tf.nn.relu),      \n",
        "\n",
        "        #'''TODO: Define the pool size of the first max pooling layer according to the figure: Replace the _'''\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(_,_)),\n",
        "\n",
        "        #'''TODO: Define the second convolutional layer according to the figure'''\n",
        "\n",
        "        #'''TODO: Define the second max pooling layer according to the figure'''\n",
        "\n",
        "        '''Note that if everything is defined correctly up to this point, \n",
        "        the flatten layer would give us the first Dense layer which contains\n",
        "        the 900 hidden units (ie: no need to define a Dense layer here, \n",
        "        only the flatten layer is needed)'''\n",
        "        #'''TODO: Define the flatten layer'''\n",
        "        \n",
        "        #'''TODO: Define the second Dense layer according to the figure'''\n",
        "\n",
        "        #'''TODO: Define the last Dense layer according to the figure'''\n",
        "    ])\n",
        "    return cnn_model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMNCbIm6irX2"
      },
      "source": [
        "#### Compile the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cCC9FLVixWm"
      },
      "source": [
        "**TODO** \n",
        "\n",
        "1. Try different [optimizers](https://keras.io/api/optimizers/), and report the difference in **accuracy** and plots.\n",
        "2. For each optimizer, try different learning rates and other hyperparameters (If applicable), and report the difference in **accuracy** and plots.\n",
        "3. Try different [loss functions](https://keras.io/api/losses/), and report the difference in **accuracy** and plots. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_60pHxCpE7h"
      },
      "source": [
        "cnn_model = build_cnn_model()\n",
        "\n",
        "'''TODO: Experiment with different optimizers and learning rates. How do these affect\n",
        "    the accuracy of the trained model? Which optimizers and/or learning rates yield\n",
        "    the best performance?'''\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#### Print the Convolutional Neural Network Model Summary"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "bt63-X7jDsIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7lOqih9FDsIJ",
        "outputId": "825ef73a-a0b3-4668-b101-4b9beaf0e077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 24)        240       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 13, 13, 24)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4056)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               519296    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 519,536\n",
            "Trainable params: 519,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn_model.build((None, train_images.shape[1], train_images.shape[2], train_images.shape[3]))\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm7Pb6nBi2Wt"
      },
      "source": [
        "#### Train the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO0W3rXnpTZ2"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "\n",
        "cnn_hist = cnn_model.fit(train_images, train_labels, validation_data=(val_images, val_labels), batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-bq0vwfi-Pd"
      },
      "source": [
        "#### Plot the Accuracy Curve for the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnSK5TMEpdMN"
      },
      "source": [
        "# Get training and validation accuracy histories\n",
        "training_acc = cnn_hist.history['accuracy']\n",
        "val_acc = cnn_hist.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, EPOCHS + 1)\n",
        "\n",
        "# Visualize accuracy history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_acc, 'r--')\n",
        "plt.plot(epoch_count, val_acc, 'b-')\n",
        "plt.legend(['CNN Training Accuracy', 'CNN Val Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('CNN Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtqv4xmQjNgV"
      },
      "source": [
        "#### Evaluate the Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZNPYmqlp-bk"
      },
      "source": [
        "val_loss, val_acc = cnn_model.evaluate(val_images, val_labels)\n",
        "\n",
        "print('Validation Accuracy:', val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Think About the Following"
      ],
      "metadata": {
        "id": "balho-F9RQZx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asucqmxfrtnc"
      },
      "source": [
        "What is the highest accuracy you’re able to achieve using the CNN model, and how does the accuracy of the CNN model compare to the accuracy of the simple fully connected network?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Machine Learning Interpretability"
      ],
      "metadata": {
        "id": "o3vidv7HSUyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part, we will have a look at using SHAP for machine learning interpretability analysis.\n",
        "\n",
        "A crucial part of studying machine learning models is understanding what they are doing to make sure that the model really understands the problem and is not overfitting the data or focusing on incorrect features. This helps us identify the model weaknesses and thus improve its performance on unseen data. One of the ways to do so is to determine and analyze the features affecting the model's prediction. You can read more about machine learning interpretability in this [article](https://towardsdatascience.com/understanding-machine-learning-interpretability-168fd7562a1a) if you are interested.\n",
        "\n",
        "[SHAP](https://shap.readthedocs.io/en/latest/overviews.html) is a technique that leverages game theory to explain the prediction by identifying the contribution of each feature on the model's final decision. You can read about other techniques in this [article](https://towardsdatascience.com/three-interpretability-methods-to-consider-when-developing-your-machine-learning-model-5bf368b47fac).\n",
        "\n",
        "For this part, we will use the **DeepExplainer** provided by SHAP for analyzing the performance of **the best CNN model** you created on the MNIST dataset. \n",
        "\n",
        "**You can find details about how to do so [here](https://shap.readthedocs.io/en/latest/example_notebooks/image_examples/image_classification/Front%20Page%20DeepExplainer%20MNIST%20Example.html).**"
      ],
      "metadata": {
        "id": "HbEHhi4OSzNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Installing SHAP"
      ],
      "metadata": {
        "id": "m6k1f2ImXA9P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCb78Y5Jaq9W"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Importing and using SHAP"
      ],
      "metadata": {
        "id": "N9VMoLObY-g-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOOp8BAwY-g_"
      },
      "source": [
        "import shap\n",
        "# TODO: select a random set of background samples to take an expectation over\n",
        "background = train_images['''TODO: Select a set of 1000 random images without replacement, refer to the provided link''']\n",
        "# TODO: Instantiate the deep explainer with the best CNN model and the background samples\n",
        "e = shap.DeepExplainer('''TODO: Fill in the correct parameters, refer to the provided link''')\n",
        "# Obtaining the SHAP values on the first 10 images\n",
        "shap_values = e.shap_values(val_images[1:11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot to see where did the model concentrate to classify the images\n",
        "shap.image_plot(shap_values,-val_images[1:11])"
      ],
      "metadata": {
        "id": "4fdHLnuyXE3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Think about the following:** *What does the plot show in each entry? What can you conclude from the plot? Is the model focusing on meaningful features? Why? Why not? Are there features in certain digits that confuse the model?*\n",
        "\n",
        "**Make sure to include the plot and your comments in the report.**"
      ],
      "metadata": {
        "id": "AABZ8XqCa_Wg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1NPM797C_5V"
      },
      "source": [
        "## 2.3 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPhiXDFhrim8"
      },
      "source": [
        "That's it! Congratulations on training a multinominal classification models.\n",
        "\n",
        "Make sure you deliver all the requirements for the submission."
      ]
    }
  ]
}